{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the `rnn.py` file is explained in more details. The `RNNModel` class receives as parameter the following:\n",
    "\n",
    "- `input_size`: the same size as the one-hot encoded array.\n",
    "- `output_size`: as our expected output is the same size as the input, the output will be the same size than the one-hot encoded array.\n",
    "- `hidden_dim`: the size of features in the hidden state.\n",
    "- `n_layers`: the number of RNN layers to be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line 15 defines the RNN layer. `batch_first` is necessary to specify the way in which data are represented in the input. In this example, the first dimension represents the batch size, the second the sentence and the third each character in the setence represented as an one-hot array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the RNN layer, the data will passes through a fully connected layer to present the output, as shown on line 19. The fully connected layer receives the output from the recurrent layer. Therefore, the input size will be the same as the number of features in the hidden state (`hidden_dim`). The output size of the fully connected layer will be the same size as the output sentence one-hot encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellow is the whole code of the recurrent neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(RNNModel, self).__init__()\n",
    "\n",
    "        # Defining some parameters.\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # region Defining the layers.\n",
    "        # RNN layer.\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size, hidden_dim, n_layers, batch_first=True, nonlinearity=\"relu\"\n",
    "        )\n",
    "        # Fully connected layer.\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        # endregion\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(axis=0)\n",
    "\n",
    "        # Initializing hidden state for first input using method defined below.\n",
    "        hidden = self.init_hidden(batch_size)  # (1, 3, 12)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs.\n",
    "        out, hidden = self.rnn(x, hidden)  # (3, 14, 12), (1, 3, 12)\n",
    "\n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer.\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)  # (42, 12)\n",
    "        out = self.fc(out)  # (42, 17)\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we will use in the forward pass.\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forward method is responsible for passing the input through the network layers. The first step is to initialize the hidden state for the recurrent layer. The shape of the hidden state will be the number of recurrent layers, the size of the batch and the number of hidden features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image below shows in more details the size of the inputs and outputs shapes through the network layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![shapes](../../documentation/tensor-sizes-through-network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the network is simple. Therefore, there will be problems with overfitting. The goal is just to understand the simplest concepts about recurrent neural networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
